# 第4章 ニューラルネットワークの学習 - 総復習

## 📚 この章の全体像

```
データ → 損失関数 → 勾配計算 → パラメータ更新 → 学習完了
         ↓           ↓            ↓
      誤差の測定   どう変える？  重みを調整
```

**学習のゴール**: 訓練データから最適な重みパラメータWとバイアスbを自動的に見つける

---

## 1. 学習とは何か

### 従来の機械学習 vs ディープラーニング

```
【従来の機械学習】
生データ → [特徴量抽出] → 機械学習 → 出力
            ↑ 人間が設計

【ディープラーニング】
生データ → ニューラルネットワーク → 出力
            ↑ 特徴量も自動で学習
```

**重要ポイント**:
- ニューラルネットワークは**特徴量も重みも**すべてデータから学習
- 人間が設計する必要がない（End-to-End学習）

---

## 2. データの分割

### 訓練データ vs テストデータ

```python
訓練データ（Training）: 学習に使用
テストデータ（Test）   : 性能評価のみ（学習には使わない！）
```

**なぜ分けるのか？**
→ **汎化能力**（未知データへの対応力）を正しく評価するため

### 過学習（Overfitting）

```
訓練精度: 99% ←高い！
テスト精度: 70% ←低い...

→ 訓練データを「暗記」してしまっている状態
```

**対策**:
- データを分ける
- 正則化（Regularization）
- Dropout

---

## 3. 損失関数（Loss Function）

### なぜ損失関数を使うのか？

**認識精度ではダメな理由**: 微分できない（離散的な値）

```
【認識精度のグラフ】
精度
 34% ━━━━━━  ← 階段状
 33% ━━━━━━  （微分不可）
 32% ━━━━━━
     └─────→ 重み

【損失関数のグラフ】
損失
  ╲
   ╲         ← なめらか
    ╲        （微分可能）
     └─────→ 重み
```

**重要**: 重みをわずかに変えても、認識精度は変わらないことが多い
→ 勾配が0 → どう更新すべきかわからない

---

## 4. 二乗和誤差（MSE）

### 数式

$$
E = \frac{1}{2} \sum_{k} (y_k - t_k)^2
$$

- $y_k$: 予測値
- $t_k$: 正解値
- 予測と正解の差を二乗して合計

### 実装

```python
def mean_squared_error(y, t):
    return 0.5 * np.sum((y - t) ** 2)
```

### 使用場面

**回帰問題**（連続値の予測）に適している

例: 株価予測、気温予測など

---

## 5. 交差エントロピー誤差（Cross Entropy）⭐

### 数式

$$
E = -\sum_{k} t_k \log y_k
$$

**one-hot表現の場合**: 正解クラスの確率だけに注目

$$
E = -\log(\text{正解クラスの予測確率})
$$

### 直感的理解

```
正解の確率  損失の値
  100%  →    0     （完璧！）
   50%  →   0.69   （微妙）
   10%  →   2.30   （悪い）
    1%  →   4.61   （最悪）
```

### 実装

```python
def cross_entropy_error(y, t):
    delta = 1e-7  # log(0)を防ぐ
    return -np.sum(t * np.log(y + delta))
```

### 使用場面

**分類問題**（クラス分けの予測）に適している

例: 画像分類、スパム判定など

---

## 6. ミニバッチ学習

### 問題

```
訓練データ60,000個すべてで損失計算
→ 1回の更新に時間がかかりすぎる
```

### 解決策

```python
# 一部のデータ（例: 100個）をランダムに選ぶ
batch_mask = np.random.choice(60000, 100)
x_batch = x_train[batch_mask]
t_batch = t_train[batch_mask]

# このミニバッチで損失を計算
loss = network.loss(x_batch, t_batch)
```

### メリット

1. **計算速度向上**: 60,000個 → 100個（600倍速い）
2. **メモリ効率**: 大規模データも扱える
3. **汎化性能向上**: ランダムサンプリングがノイズとして機能

---

## 7. 数値微分

### 微分とは

**ある瞬間の変化の割合（傾き）**

$$
f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}
$$

### 中心差分による近似

```python
def numerical_diff(f, x):
    h = 1e-4  # 0.0001
    return (f(x + h) - f(x - h)) / (2 * h)
```

**なぜ中心差分？**

```
【前方差分】          【中心差分】
   f(x+h)              f(x+h)
     ●                   ●
    ╱                     ╲
   ╱ ←精度低い             ╲ ←精度高い
  ●                       ╱
 f(x)                   ╱
                       ●
                    f(x-h)
```

### 例: $y = x^2$ の微分

```python
def f(x):
    return x ** 2

# x=5での微分
numerical_diff(f, 5)
# → 9.9999... ≈ 10

# 理論値: f'(x) = 2x より f'(5) = 10
```

---

## 8. 偏微分と勾配

### 偏微分

**多変数関数で、1つの変数だけについて微分**

例: $f(x_0, x_1) = x_0^2 + x_1^2$

```
∂f/∂x₀ = 2x₀  （x₁は定数として扱う）
∂f/∂x₁ = 2x₁  （x₀は定数として扱う）
```

### 勾配（Gradient）

**すべての変数の偏微分をまとめたベクトル**

$$
\nabla f = \left( \frac{\partial f}{\partial x_0}, \frac{\partial f}{\partial x_1}, \ldots \right)
$$

### 勾配の意味

```
勾配 = 「関数が最も増加する方向」

逆に言えば...
勾配の逆方向 = 「関数が最も減少する方向」
                ↓
          これを使って学習する！
```

### 実装

```python
def numerical_gradient(f, x):
    h = 1e-4
    grad = np.zeros_like(x)
    
    for idx in range(x.size):
        tmp_val = x[idx]
        
        # f(x+h)
        x[idx] = tmp_val + h
        fxh1 = f(x)
        
        # f(x-h)
        x[idx] = tmp_val - h
        fxh2 = f(x)
        
        # 勾配を計算
        grad[idx] = (fxh1 - fxh2) / (2 * h)
        
        x[idx] = tmp_val  # 元に戻す
        
    return grad
```

---

## 9. 勾配降下法（Gradient Descent）⭐⭐⭐

### アルゴリズム

$$
x \leftarrow x - \eta \nabla f(x)
$$

- $x$: パラメータ（重みやバイアス）
- $\eta$: 学習率（Learning Rate）
- $\nabla f(x)$: 勾配

**直感的な理解**:
```
現在地 ← 現在地 - 学習率 × 勾配
         ↑ 谷底（最小値）に向かって進む
```

### 視覚的イメージ

```
      ╱╲        ← 山
    ╱    ╲
  ╱   ●   ╲     ● = 現在地
 ╱    ↓    ╲    ↓ = 勾配の逆方向（下り方向）
╱___________╲
     ●            ● = 次の位置（谷底に近づく）
    谷底
```

### 実装

```python
def gradient_descent(f, init_x, lr=0.01, step_num=100):
    x = init_x.copy()
    
    for i in range(step_num):
        grad = numerical_gradient(f, x)  # 勾配を計算
        x -= lr * grad                    # 更新
        
    return x
```

### 例: 最小値を探す

```python
def f(x):
    return x[0]**2 + x[1]**2

init_x = np.array([-3.0, 4.0])  # スタート地点
result = gradient_descent(f, init_x, lr=0.1, step_num=100)
print(result)
# → [0.0, 0.0]  最小値に到達！
```

---

## 10. 学習率の重要性

### 学習率の影響

```
┌─────────────────────────────────┐
│ 学習率  │ 結果                  │
├─────────┼───────────────────────┤
│ 大 (10.0) │ 発散（値が爆発）      │
│ 適切(0.1) │ 最小値に到達 ✓       │
│ 小(1e-10) │ 学習が遅い、届かない  │
└─────────────────────────────────┘
```

### 視覚的イメージ

```
【学習率が大きすぎる】
  ●→→→→●     飛び越えてしまう
    ↓最小値

【学習率が適切】
  ● → ● → ● → ●
          ↓最小値  徐々に近づく

【学習率が小さすぎる】
  ●→●→●       ほとんど動かない
      ↓まだ遠い
```

### ハイパーパラメータ調整

**学習率は最も重要なハイパーパラメータ**

一般的な初期値: `0.01`, `0.001`, `0.0001`

---

## 11. ニューラルネットワークへの応用

### 重みに対する勾配

**目標**: 損失関数 $L$ に対する重み $W$ の勾配 $\frac{\partial L}{\partial W}$ を求める

**勾配の意味**:
```
勾配が正 → その重みを減らせば損失が減る
勾配が負 → その重みを増やせば損失が減る
```

### 簡単な例

```python
class simpleNet:
    def __init__(self):
        # 2×3の重み行列
        self.W = np.random.randn(2, 3)
    
    def predict(self, x):
        return np.dot(x, self.W)
    
    def loss(self, x, t):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        return loss

# ネットワーク作成
net = simpleNet()
x = np.array([0.6, 0.9])  # 入力
t = np.array([0, 0, 1])    # 正解（クラス2）

# 勾配を計算
f = lambda W: net.loss(x, t)
dW = numerical_gradient(f, net.W)

print(dW)
# [[ 0.22  0.14 -0.36]   正解クラスへの勾配が負
#  [ 0.33  0.22 -0.54]]  → 重みを増やす方向に更新
```

**結果の解釈**:
```
正解クラス（クラス2）への重み: 勾配が負
  → 重みを増やす（正解の出力を強化）

不正解クラス（クラス0,1）への重み: 勾配が正
  → 重みを減らす（不正解の出力を抑制）
```

---

## 12. 学習アルゴリズムの実装

### SGD（確率的勾配降下法）の4ステップ

```
┌─────────────────────────────────┐
│ ステップ1: ミニバッチ            │
│  訓練データから一部を選ぶ        │
├─────────────────────────────────┤
│ ステップ2: 勾配の計算            │
│  各重みに対する損失の傾きを求める│
├─────────────────────────────────┤
│ ステップ3: パラメータの更新      │
│  W ← W - η∇L                    │
├─────────────────────────────────┤
│ ステップ4: 繰り返し              │
│  ステップ1〜3を繰り返す          │
└─────────────────────────────────┘
```

### 2層ニューラルネットワーク

```python
class TwoLayerNet:
    def __init__(self, input_size, hidden_size, output_size):
        # 重みの初期化
        self.params = {}
        self.params['W1'] = 0.01 * np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)
        self.params['W2'] = 0.01 * np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(output_size)
    
    def predict(self, x):
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']
        
        a1 = np.dot(x, W1) + b1
        z1 = sigmoid(a1)
        a2 = np.dot(z1, W2) + b2
        y = softmax(a2)
        return y
    
    def loss(self, x, t):
        y = self.predict(x)
        return cross_entropy_error(y, t)
    
    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)
        t = np.argmax(t, axis=1)
        return np.sum(y == t) / float(x.shape[0])
    
    def numerical_gradient(self, x, t):
        loss_W = lambda W: self.loss(x, t)
        
        grads = {}
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])
        
        return grads
```

### 学習ループ

```python
# ネットワーク作成
network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)

# ハイパーパラメータ
iters_num = 10000      # 繰り返し回数
batch_size = 100       # ミニバッチサイズ
learning_rate = 0.1    # 学習率

for i in range(iters_num):
    # ステップ1: ミニバッチ
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]
    
    # ステップ2: 勾配の計算
    grad = network.numerical_gradient(x_batch, t_batch)
    
    # ステップ3: パラメータの更新
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key]
    
    # 損失の記録
    loss = network.loss(x_batch, t_batch)
    train_loss_list.append(loss)
```

---

## 13. 重要な用語まとめ

### 学習関連

| 用語 | 説明 |
|------|------|
| **訓練（Training）** | モデルを学習させること |
| **推論（Inference）** | 学習済みモデルで予測すること |
| **エポック（Epoch）** | 全訓練データを1回学習した単位 |
| **イテレーション** | パラメータ更新1回 |

### データ

| 用語 | 説明 |
|------|------|
| **訓練データ** | 学習に使用するデータ |
| **テストデータ** | 性能評価のみに使用（学習には使わない） |
| **検証データ** | ハイパーパラメータ調整用 |
| **ミニバッチ** | 訓練データの一部（ランダムサンプリング） |

### パラメータ

| 用語 | 説明 |
|------|------|
| **重み（Weight）** | 学習で調整されるパラメータ |
| **バイアス（Bias）** | 学習で調整されるパラメータ |
| **ハイパーパラメータ** | 学習前に設定するパラメータ（学習率など） |

### 評価指標

| 用語 | 説明 |
|------|------|
| **損失（Loss）** | モデルの性能の悪さを示す指標 |
| **精度（Accuracy）** | 正解率 |
| **汎化（Generalization）** | 未知データへの対応能力 |
| **過学習（Overfitting）** | 訓練データに過剰適応した状態 |

---

## 14. 損失関数の選び方

```
┌─────────────────────────────────┐
│  問題タイプ  │  損失関数        │
├──────────────┼──────────────────┤
│  回帰問題    │  二乗和誤差(MSE) │
│              │  f(x)=x²+...     │
├──────────────┼──────────────────┤
│  分類問題    │  交差エントロピー │
│              │  クラス分け      │
└─────────────────────────────────┘
```

---

## 15. 数値微分 vs 誤差逆伝播法

| 特徴 | 数値微分 | 誤差逆伝播法 |
|------|---------|------------|
| **実装** | 簡単 | 複雑 |
| **計算速度** | 遅い | 高速 |
| **精度** | 近似値 | 厳密 |
| **用途** | 理解・確認 | 実用 |

**数値微分の役割**:
- 勾配の概念を理解する（今回）
- 誤差逆伝播法の実装を確認する（勾配チェック）

**次章（第5章）で学ぶ誤差逆伝播法は、実用的な学習に不可欠**

---

## 16. 学習の可視化

### 学習曲線（Learning Curve）

```python
import matplotlib.pyplot as plt

# 損失の推移
plt.plot(train_loss_list)
plt.xlabel("Iteration")
plt.ylabel("Loss")
plt.title("Learning Curve")
plt.show()
```

**理想的な学習曲線**:
```
損失
 ↑
 │╲
 │ ╲
 │  ╲___________  ← 滑らかに減少して収束
 │
 └──────────→ イテレーション
```

**問題がある学習曲線**:
```
【学習率が大きすぎる】      【過学習】
損失                        損失
 ↑                           ↑
 │╱╲╱╲╱╲  ← 振動             │╲    訓練
 │                           │ ╲___
 │                           │   ╱  テスト
 └──→                        └──→
```

---

## 17. ハイパーパラメータの調整

### 主要なハイパーパラメータ

```
┌────────────────────────────────────┐
│ ハイパーパラメータ │ 一般的な値    │
├────────────────────┼───────────────┤
│ 学習率             │ 0.01, 0.001   │
│ バッチサイズ       │ 32, 64, 128   │
│ エポック数         │ 10〜100       │
│ 隠れ層のニューロン数│ 50〜500       │
└────────────────────────────────────┘
```

### 調整の流れ

```
1. ざっくりとした範囲で試す（10^n のオーダー）
   例: 0.001, 0.01, 0.1, 1.0

2. 良さそうな範囲を絞り込む
   例: 0.01が良い → 0.005, 0.01, 0.015を試す

3. 学習曲線を見て判断
   - 滑らかに減少 → OK
   - 振動 → 学習率を下げる
   - 変化なし → 学習率を上げる
```

---

## 18. まとめ：学習の全体像

```
┌─────────────────────────────────────────┐
│                                         │
│  1. データを用意（訓練/テスト分割）      │
│           ↓                             │
│  2. ネットワーク構築（重みを初期化）     │
│           ↓                             │
│  3. ミニバッチを選ぶ ←─────┐            │
│           ↓                │            │
│  4. 順伝播（予測）          │            │
│           ↓                │            │
│  5. 損失を計算             │            │
│           ↓                │            │
│  6. 勾配を計算             │            │
│           ↓                │            │
│  7. パラメータ更新         │            │
│           ↓                │            │
│  8. 3〜7を繰り返す ────────┘            │
│           ↓                             │
│  9. テストデータで評価                   │
│                                         │
└─────────────────────────────────────────┘
```

---

## 19. 復習問題

### Q1: なぜ認識精度ではなく損失関数を使うのか？

<details>
<summary>答えを見る</summary>

**答え**: 認識精度は離散的な値で、微分がほとんど0になるため、勾配（重みをどう変えるべきか）がわからない。損失関数は連続的に変化するので、微分可能で、勾配を使った学習ができる。

</details>

### Q2: 勾配降下法の更新式を書け

<details>
<summary>答えを見る</summary>

**答え**: 
$$x \leftarrow x - \eta \nabla f(x)$$

- $x$: パラメータ
- $\eta$: 学習率
- $\nabla f(x)$: 勾配

</details>

### Q3: 学習率が大きすぎるとどうなるか？

<details>
<summary>答えを見る</summary>

**答え**: 最小値を飛び越えてしまい、発散する。パラメータの値が爆発的に大きくなる。

</details>

### Q4: ミニバッチ学習のメリットを3つ挙げよ

<details>
<summary>答えを見る</summary>

**答え**:
1. 計算速度の向上（全データより高速）
2. メモリ効率（大規模データも扱える）
3. 汎化性能の向上（ランダムサンプリングによる正則化効果）

</details>

### Q5: 過学習とは何か？どう検出するか？

<details>
<summary>答えを見る</summary>

**答え**: 訓練データに過剰に適応し、テストデータでの性能が低下する現象。訓練精度とテスト精度を比較して検出する。訓練精度が高いのにテスト精度が低い場合、過学習の可能性がある。

</details>

---

## 20. 次章への準備

### 第5章で学ぶこと

```
誤差逆伝播法（Backpropagation）
  ↓
数値微分より遥かに高速に勾配を計算
```

**キーワード**:
- 計算グラフ
- 連鎖律（Chain Rule）
- 逆伝播
- 高速な勾配計算

**なぜ重要？**
- 実用的なディープラーニングに不可欠
- 数値微分は遅すぎて使えない
- 誤差逆伝播法で、大規模ネットワークも学習可能に

---

## 📝 チェックリスト

学習内容を理解できたか確認しましょう：

- [ ] 損失関数の役割を説明できる
- [ ] 二乗和誤差と交差エントロピー誤差の違いを理解している
- [ ] 数値微分のコードを書ける
- [ ] 勾配の意味を理解している
- [ ] 勾配降下法のアルゴリズムを説明できる
- [ ] 学習率の重要性を理解している
- [ ] ミニバッチ学習のメリットを説明できる
- [ ] SGDの4ステップを言える
- [ ] 過学習とは何か説明できる
- [ ] 訓練データとテストデータを分ける理由を理解している

---

## 🔗 関連ファイル

- `gradient_simple.py`: 勾配計算の基礎
- `gradient_descent.py`: 勾配降下法の可視化
- `training_neuralnet.md`: 詳細な説明
- `mini_batch.py`: ミニバッチ学習の実装

---

**学習完了！次は第5章「誤差逆伝播法」へ進みましょう 🚀**
